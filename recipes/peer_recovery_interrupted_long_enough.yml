- import_playbook: basic_leader_election2.yml
- name: "Peer Recovery Interrupted Long Enough"
  hosts: localhost
  connection: local
  vars:
     recipe_name: "peer_recovery_interrupted_long_enough"
     parent: "basic_leader_election2"
     pri_num_writes: 10000
     raft_root_entry_keys:
              - "/raft_root_entry/0/leader-uuid"
              - "/raft_root_entry/0/term"
              - "/raft_root_entry/0/commit-idx"
              - "/raft_root_entry/0/lowest-idx"
              - "/raft_root_entry/0/checkpoint-idx"
              - "/raft_net_info/max-scan-entries"
              - "/raft_net_info/log-reap-factor"
  tasks:
  - block:
    - name: "Check if parent recipe failed"
      debug: msg="Check if parent recipe {{ parent }} failed"
      failed_when: terminate_recipe == true

    - name: "{{ recipe_name }}: Get the latest list of running peer UUIDs"
      include_role:
         name: common
         tasks_from: get_server_uuid_info

    - name: "{{ recipe_name }}: Store the UUID for peer4 which needs to be started."
      vars:
        peer4: "{{ NonRunningServers[0] }}"
      debug:
        msg: "Get the peer to start : {{ peer4 }}"
      with_items:
        - "{{ peer4 }}"
      register: pri_peer4

    - name: "{{ recipe_name }}: Start 4th peer."
      include_role:
        name: common
        tasks_from: start_server
      vars:
        ServerUUID: "{{ pri_peer4['results'][0]['item'] }}"

    - name: "{{ recipe_name }}: Get the latest list of running peer UUIDs"
      include_role:
         name: common
         tasks_from: get_server_uuid_info

    - name: "{{ recipe_name }}: Get unused client uuid for starting the client"
      include_role:
        name: common
        tasks_from: get_new_client_uuid
      register: client_uuid

    - debug:
        msg: "Client UUID: {{ client_uuid }}"

    - name: "{{ recipe_name }}: Start client process"
      include_role:
        name: common
        tasks_from: start_client
      vars:
        ClientUUID: "{{ client_uuid.stdout }}"

    - name: "{{ recipe_name }}: Verify leader is viable."
      include_role:
        name: common
        tasks_from: verify_leader_viable
      vars:
        ClientUUID: "{{ client_uuid.stdout }}"

      #Create set of required number of app_uuids.
    - name: "Get set of required number of app_uuids."
      include_role:
        name: common
        tasks_from: create_app_uuid_set
      vars:
        number_of_apps: 1

    #Perform write operations.
    - name: "Perform write operations."
      include_role:
         name: common
         tasks_from: perform_writes
      vars:
        pmdb_apps: "{{ pmdb_app_uuids  }}"
        ClientUUID: "{{ client_uuid.stdout }}"
        constant_number_of_writes: "{{ pri_num_writes }}"

    - name: "{{ recipe_name}}: Wait until all write completes from client"
      vars:
        stage: "wait_for_write_op"
      debug:
        msg: "Waiting for client to finish writing"
      until: lookup('niova_ctlrequest', 'lookup', client_uuid.stdout, '/pumice_db_test_client/pmdb-test-apps/0/pmdb-seqno', wantlist=True) | dict2items | map(attribute='value') | list | first == (pri_num_writes - 1)
      retries: 500
      delay: 1

    #Verify client parameters after successful write operations.
    - name: "{{ recipe_name }}: Verify client parameters."
      include_role:
        name: common
        tasks_from: verify_client_parameters
      vars:
        Client_UUID: "{{ client_uuid.stdout }}"

    - name: "{{ recipe_name }}: Get the latest list of running peer UUIDs"
      include_role:
         name: common
         tasks_from: get_server_uuid_info

    - name: "{{ recipe_name }}: Get the leader and follower uuids."
      include_role:
         name: common
         tasks_from: get_follower_stats

    - name: "{{ recipe_name }}: Kill the leader."
      debug:
        msg:  "{{ lookup('niova_raftprocess', 'kill', LeaderUUID['/0/leader-uuid'], wantlist=True) }}"

      #Store previous leader.
    - name: "{{ recipe_name }}: Store previous leader uuid."
      vars:
        prv_ldr: "{{ LeaderUUID['/0/leader-uuid'] }}"
      debug:
        msg: "Store previous leader."
      with_items:
          - "{{ prv_ldr }}"
      register: prev_leader

    - name: "{{ recipe_name }}: Get the latest list of running peer UUIDs"
      include_role:
         name: common
         tasks_from: get_server_uuid_info

    - name: "{{ recipe_name }}: Get the values for raft-root-entry."
      vars:
         stage: "stage1_get_all"
         peer_values: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, raft_root_entry_keys, wantlist=True) }}"
      debug:
        msg: "Get the raft values for running peers"
      no_log: true
      with_items:
       - "{{ peer_values }}"
      register: stage1_values

    - name: "{{ recipe_name }}: Get the latest list of running peer UUIDs"
      include_role:
         name: common
         tasks_from: get_server_uuid_info

      #Create set of required number of app_uuids.
    - name: "Get set of required number of app_uuids."
      include_role:
        name: common
        tasks_from: create_app_uuid_set
      vars:
        number_of_apps: 1

    #Perform write operations.
    - name: "Perform write operations."
      include_role:
         name: common
         tasks_from: perform_writes
      vars:
        pmdb_apps: "{{ pmdb_app_uuids  }}"
        ClientUUID: "{{ client_uuid.stdout }}"
        constant_number_of_writes: "{{ pri_num_writes }}"

    - name: "{{ recipe_name}}: Wait until all write completes from client"
      vars:
        stage: "wait_for_write_op"
      debug:
        msg: "Waiting for client to finish writing"
      until: lookup('niova_ctlrequest', 'lookup', client_uuid.stdout, '/pumice_db_test_client/pmdb-test-apps/0/pmdb-seqno', wantlist=True) | dict2items | map(attribute='value') | list | first == (pri_num_writes - 1)
      retries: 500
      delay: 1

    - name: "{{ recipe_name }}: Get the values for raft-root-entry."
      vars:
         stage: "stage2_get_all"
         peer_values: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, raft_root_entry_keys, wantlist=True) }}"
      debug:
        msg: "Get the raft values for running peers"
      no_log: true
      with_items:
       - "{{ peer_values }}"
      register: stage2_values

    #See if recovery happens with new leader.
    - name: "{{ recipe_name }}: Get commit-idx of all running peers and wait until all running peers show same commit idx."
      vars:
        stage: "get_commit_idx"
        get_commit_idx: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, '/raft_root_entry/0/commit-idx', wantlist=True) }}"
        commit_idx_has_unique_val: "{{ get_commit_idx | map(attribute='/0/commit-idx') | list | unique | length == 1 }}"
      debug:
        msg: "Waiting until all running peers show same commit idx"
      loop: "{{ range(0, 10) | list }}"
      loop_control:
         pause: 1

    - name: "{{ recipe_name }}: Get commit-idx values of all peers."
      vars:
        stage: "get_cm_idx_all"
        cmidx: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, '/raft_root_entry/0/commit-idx', wantlist=True) }}"
      debug:
         msg: "Getting commit-idx for all servers."
      no_log: true
      with_items:
         - "{{ cmidx }}"
      register: commit_idx_all

    - name: "{{ recipe_name }}: Compare commit-idx values of all peers."
      vars:
        commit_idx: "{{ commit_idx_all['results'][item]['item']['/0/commit-idx'] }}"
        commit_idx_next: "{{ commit_idx_all['results'][item +1]['item']['/0/commit-idx'] }}"
      debug:
        msg: "Compare commit-idx values of all peers."
      failed_when: commit_idx != commit_idx_next
      loop: "{{ range(0, NRunningPeers | length-1) | list }}"

    - name: "{{ recipe_name }}: Wait until all running peers show same last-applied-cumulative-crc."
      include_role:
        name: common
        tasks_from: wait_until_all_peers_show_same_cum_crc

    #Verify whether quorum has recovered writes.
    - name: "{{ recipe_name }}: Verify last-applied-cumulative-crc and sync-entry-crc are same on all peers."
      include_role:
        name: common
        tasks_from: verify_crc_on_all_peers

    - name: "{{ recipe_name }}: Check for checkpoint-idx."
      vars:
        chkp_idx: "{{ stage2_values['results'][item]['item']['/0/checkpoint-idx'] }}"
      debug:
        msg: "Check for checkpoint-idx."
      failed_when: chkp_idx | int == -1
      loop: "{{ range(0, NRunningPeers | length) | list }}"

    - name: "{{ recipe_name }}: Check if lowest index is increasing."
      vars:
        prev_lowest_idx: "{{ stage1_values['results'][item]['item']['/0/lowest-idx'] }}"
        next_lowest_idx: "{{ stage2_values['results'][item]['item']['/0/lowest-idx'] }}"
      debug:
        msg: "Check if lowest index is increasing."
      failed_when: next_lowest_idx <= prev_lowest_idx
      loop: "{{ range(0, NRunningPeers | length) | list }}"

    #recipe-cleanup.
    - name: "{{ recipe_name }}: Start previous leader."
      include_role:
        name: common
        tasks_from: start_server
      vars:
        ServerUUID: "{{ prev_leader['results'][0]['item'] }}"

    rescue:
      - name: "Recipe failed"
        set_fact:
          terminate_recipe: true

