- import_playbook: ../raft_recipes/healthy_raftserver_cluster_type2.yml
  when: ClusterParams['ctype'] == "pumicedb"

- name: "Completing an Uncommitted Write Following a Reboot"
  hosts: localhost
  connection: local
  vars:
     recipe_name: "Completing an Uncommitted Write Following a Reboot"
     parent: "Healthy Raftserver Cluster Type-2"
     requirement: "pumicedb"
     num_writes: 0
     cuwr_num_peer_started_after_reboot: []
     peer_raft_keys:
           - "/raft_root_entry/0/term"
           - "/raft_root_entry/0/commit-idx"
           - "/raft_root_entry/0/last-applied"
           - "/raft_root_entry/0/last-applied-cumulative-crc"
           - "/raft_root_entry/0/sync-entry-idx"
           - "/raft_root_entry/0/sync-entry-term"
           - "/raft_root_entry/0/sync-entry-data-size"
           - "/raft_root_entry/0/sync-entry-crc"

  tasks:
  - block:
    - name: "Check if parent recipe failed"
      debug: msg="Check if parent recipe {{ parent }} failed"
      failed_when: terminate_recipe == true

    - name: "{{ recipe_name }}: Verifying recipe compatibility requirements."
      include_role:
         name: common
         tasks_from: recipe_compatibility_requirement

    - name: "{{ recipe_name }}: Get unused client uuid for starting the client"
      include_role:
        name: common
        tasks_from: get_new_client_uuid
      register: client_uuid

    - name: "{{ recipe_name }}: Generate App UUID."
      shell: "/usr/bin/uuid"
      register: app_uuid

    #Recipe Preparation
    - name: "{{ recipe_name }}: Get raft_root_entry values of all peers before reboot."
      vars:
        stage: "recipe_preparation"
        raft_root_entry: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, peer_raft_keys) }}"
      debug:
         msg: "Getting raft_root_entry for all servers."
      no_log: true
      with_items:
         - "{{ raft_root_entry }}"
      register: raft_root_entry_all

    - name: "{{ recipe_name }}: Compare raft_root_entry values of all peers."
      vars:
        term: "{{ raft_root_entry_all['results'][item]['item']['/0/term'] }}"
        term_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/term'] }}"
        commit_idx: "{{ raft_root_entry_all['results'][item]['item']['/0/commit-idx'] }}"
        commit_idx_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/commit-idx'] }}"
        last_applied: "{{ raft_root_entry_all['results'][item]['item']['/0/last-applied'] }}"
        last_applied_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/last-applied'] }}"
        last_applied_cum_crc: "{{ raft_root_entry_all['results'][item]['item']['/0/last-applied-cumulative-crc'] }}"
        last_applied_cum_crc_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/last-applied-cumulative-crc'] }}"
        sync_entry_idx: "{{ raft_root_entry_all['results'][item]['item']['/0/sync-entry-idx'] }}"
        sync_entry_idx_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/sync-entry-idx'] }}"
        sync_entry_term: "{{ raft_root_entry_all['results'][item]['item']['/0/sync-entry-term'] }}"
        sync_entry_term_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/sync-entry-term'] }}"
        sync_entry_data_size: "{{ raft_root_entry_all['results'][item]['item']['/0/sync-entry-data-size'] }}"
        sync_entry_data_size_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/sync-entry-data-size'] }}"
        sync_entry_crc: "{{ raft_root_entry_all['results'][item]['item']['/0/sync-entry-crc'] }}"
        sync_entry_crc_next: "{{ raft_root_entry_all['results'][item + 1]['item']['/0/sync-entry-crc'] }}"
      debug:
        msg: "Compare raft_root_entry values of all peers."
      failed_when: >
           (term != term_next) or
           (commit_idx != commit_idx_next) or
           (last_applied != last_applied_next) or
           (last_applied_cum_crc != last_applied_cum_crc_next) or
           (sync_entry_idx != sync_entry_idx_next) or
           (sync_entry_term != sync_entry_term_next) or
           (sync_entry_data_size != sync_entry_data_size_next) or
           (sync_entry_crc != sync_entry_crc_next)
      loop: "{{ range(0, NRunningPeers | length-1) | list }}"

    #Determine leader before reboot
    - name: "{{ recipe_name }}: Get leader_uuid before reboot."
      vars:
        stage: "before_reboot_leader"
        raft_keys:
           - "/raft_root_entry/0/leader-uuid"
        lead_values: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers[0], raft_keys) }}"
      debug:
        msg: "Getting leader_uuid before reboot."
      with_items:
          - "{{ lead_values }}"
      register: leader_values

    - name: "{{ recipe_name }}: Get leader uuid and follower's uuids."
      include_role:
         name: common
         tasks_from: get_follower_stats

    - name: "{{ recipe_name }}: Get sync-entry-idx values for all followers before write."
      vars:
        stage: "before_write_followers"
        raft_keys:
            - "/raft_root_entry/0/sync-entry-idx"
        sync_ent_idx_follo_before_write_vals: "{{ lookup('niova_ctlrequest', 'lookup', FollowerUUIDs, raft_keys) }}"
      debug:
        msg: "Getting sync-entry-idx values for all followers before write."
      with_items:
          - "{{ sync_ent_idx_follo_before_write_vals }}"
      register: sync_entry_idx_followers_before_write

    - name: "{{ recipe_name }}: Get sync-entry-idx value for leader before write."
      vars:
        cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
        stage: "before_write_leader"
        raft_keys:
            - "/raft_root_entry/0/sync-entry-idx"
        sync_ent_idx_lead_before_write_vals: "{{ lookup('niova_ctlrequest', 'lookup', cuwr_leader_uuid_before, raft_keys) }}"
      debug:
        msg: "Getting sync-entry-idx value for leader before write."
      with_items:
          - "{{ sync_ent_idx_lead_before_write_vals }}"
      register: sync_entry_idx_leader_before_write

    #Set raft_follower_ignores_non_hb_AE_request on the Followers
    - name: "{{ recipe_name }}: Ignore writes on all followers using fault injection."
      include_role:
        name: common
        tasks_from: set_fault_injection_and_verify
      vars:
        ServerUUID: "{{ FollowerUUIDs[item] }}"
        fault_injection_name: "raft_follower_ignores_non_hb_AE_request"
      loop: "{{ range(0, FollowerUUIDs | length) | list }}"

    - name: "{{ recipe_name }}: Start client process."
      include_role:
        name: common
        tasks_from: start_client
      vars:
        ClientUUID: "{{ client_uuid.stdout }}"

    - name: "{{ recipe_name }}: Verify leader is viable."
      include_role:
        name: common
        tasks_from: verify_leader_viable
      vars:
        ClientUUID: "{{ client_uuid.stdout }}"

    - name: "{{ recipe_name }}: Decrease client request timeout to 1 sec."
      vars:
        stage: "decrease_client_timeout"
        cmd: "default-request-timeout-sec@1"
        where: "/raft_client_root_entry/default-request-timeout-sec"
      debug:
        msg: "{{ lookup('niova_ctlrequest', 'apply_cmd', client_uuid.stdout, cmd, where) }}"
      no_log: True

    - name: "{{ recipe_name }}: Perform write on the client."
      vars:
        stage: "write"
        cmd: "input@{{ app_uuid.stdout }}:0:0:0:0.write:0"
        where: "/pumice_db_test_client/input"
      debug:
        msg: "{{ lookup('niova_ctlrequest', 'apply_cmd', client_uuid.stdout, cmd, where) }}"
      no_log: true

    - pause: seconds=2

    #Verify that write operation failed with timeout error.
    - name: "{{ recipe_name }}: Get values for pmdb-request-history."
      vars:
        stage: "get_pmdbrh"
        raft_keys:
             - "/pumice_db_test_client/pmdb-request-history"
        pmdb_request_history_values: "{{ lookup('niova_ctlrequest', 'lookup', client_uuid.stdout, raft_keys) }}"
      debug:
        msg: "Getting values for pmdb-request-history."
      no_log: true
      with_items:
          - "{{ pmdb_request_history_values }}"
      register: pmdb_request_history_vals

    - name: "{{ recipe_name }}: Validate status for write operation."
      vars:
        rncui: "{{ app_uuid.stdout }}:0:0:0:0"
        pmdb_request_history: "{{ pmdb_request_history_vals['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
      debug:
        msg: "Validating status for write operation."
      failed_when: >
            (pmdb_request_history['op'] != "write") or
            (pmdb_request_history['status'] != "Connection timed out")

    - name: "{{ recipe_name }}: Get sync-entry-idx values for all followers after write."
      vars:
        stage: "after_write_followers"
        raft_keys:
            - "/raft_root_entry/0/sync-entry-idx"
        sync_ent_idx_followers_after_write_vals: "{{ lookup('niova_ctlrequest', 'lookup', FollowerUUIDs, raft_keys) }}"
      debug:
        msg: "Getting sync-entry-idx values for all followers after write."
      with_items:
          - "{{ sync_ent_idx_followers_after_write_vals }}"
      register: sync_entry_idx_followers_after_write

    - name: "{{ recipe_name }}: Wait till leader's sync-entry-idx advances by 1"
      vars:
        cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
        leader_sync_entry_idx_before: "{{ sync_entry_idx_leader_before_write['results'][0]['item'] }}"
        stage: "wait_for_sync_idx_inc"
        raft_keys:
            - "/raft_root_entry/0/sync-entry-idx"
      debug:
       msg: "Wait for sync-entry-idx to advance by 1"
      until: lookup('niova_ctlrequest', 'lookup', cuwr_leader_uuid_before, raft_keys)['/0/sync-entry-idx'] | int != leader_sync_entry_idx_before | int + 1
      retries: 60
      delay: 1

    - name: "{{ recipe_name }}: Get sync-entry-idx value for leader after write."
      vars:
        cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
        stage: "after_write_leader"
        raft_keys:
            - "/raft_root_entry/0/sync-entry-idx"
        sync_ent_idx_lead_after_write_vals: "{{ lookup('niova_ctlrequest', 'lookup', cuwr_leader_uuid_before, raft_keys) }}"
      debug:
        msg: "Getting sync-entry-idx value for leader after write."
      with_items:
          - "{{ sync_ent_idx_lead_after_write_vals }}"
      register: sync_entry_idx_leader_after_write

    #2a- Verification for sync-entry-idx and commit-idx
    - name: "{{ recipe_name }}: Verify that sync-entry-idx of all followers remains same."
      vars:
        sync_entry_idx_before: "{{ sync_entry_idx_followers_before_write['results'][item]['item'] }}"
        sync_entry_idx_after: "{{ sync_entry_idx_followers_after_write['results'][item]['item'] }}"
      debug:
        msg: "Verifying that sync-entry-idx of all followers remains same"
      failed_when: sync_entry_idx_before['/0/sync-entry-idx'] != sync_entry_idx_after['/0/sync-entry-idx']
      loop: "{{ range(0, FollowerUUIDs | length) | list }}"

    - name: "{{ recipe_name }}: Verify that sync-entry-idx of leader is advanced by 1."
      vars:
        leader_sync_entry_idx_before: "{{ sync_entry_idx_leader_before_write['results'][0]['item'] }}"
        leader_sync_entry_idx_after: "{{ sync_entry_idx_leader_after_write['results'][0]['item'] }}"
      debug:
        msg: "Verifying that sync-entry-idx of leader is advanced by 1."
      failed_when: (leader_sync_entry_idx_after['/0/sync-entry-idx'] - leader_sync_entry_idx_before['/0/sync-entry-idx']) != 1

    - name: "{{ recipe_name }}: Get commit-idx of all running peers after write."
      vars:
        stage: "get_commit_idx_all_after_write"
        raft_keys:
            - "/raft_root_entry/0/commit-idx"
        get_commit_idx_all_after_write_vals: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, raft_keys) }}"
      debug:
        msg: "Getting commit-idx of all running peers after write."
      with_items:
          - "{{ get_commit_idx_all_after_write_vals }}"
      register: get_commit_idx_all_after_write

    - name: "{{ recipe_name }}: Verify that commit-idx has not advanced on any peer."
      vars:
        commit_idx: "{{ raft_root_entry_all['results'][item]['item']['/0/commit-idx'] }}"
        commit_idx_after: "{{ get_commit_idx_all_after_write['results'][item]['item']['/0/commit-idx'] }}"
      failed_when: commit_idx != commit_idx_after
      debug:
        msg: "Verifying that commit-idx has not advanced on any peer."
      loop: "{{ range(0, NRunningPeers | length) | list }}"

    #3- Stop the processes, first all followers and then leader
    - name: "{{ recipe_name }}: Stop all follower processes."
      debug:
        msg: "{{ lookup('niova_raftprocess', 'kill', FollowerUUIDs[item]) }}"
      loop: "{{ range(0, FollowerUUIDs | length) | list }}"

    - name: "{{ recipe_name }}: Stop leader process."
      vars:
        cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
      debug:
        msg: "{{ lookup('niova_raftprocess', 'kill', cuwr_leader_uuid_before) }}"

    #4-  Restart the Peer that was the Leader
    - name: "{{ recipe_name }}: Restart leader first."
      include_role:
        name: common
        tasks_from: start_server
      vars:
        ServerUUID: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"

    - name: "{{ recipe_name }}: Add the leader to the started peer list."
      vars:
        cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
      set_fact:
        cuwr_num_peer_started_after_reboot: "{{ cuwr_num_peer_started_after_reboot + [cuwr_leader_uuid_before] }}"

    #5- Restart the minimum number of Remaining Peers to Create a Quorum
    - name: "{{ recipe_name }}: Get number of servers for basic leader election."
      include_role:
        name: common
        tasks_from: npeers_for_basic_leader_election

    - name: "{{ recipe_name }}: Starting peers for completing quorum."
      include_role:
        name: common
        tasks_from: start_server
      vars:
        ServerUUID: "{{ FollowerUUIDs[item] }}"
      loop: "{{ range(0, npeers_for_leader_elect | int - 1) | list }}"

    - name: "{{ recipe_name }}: Get the started followers in the running peer list."
      set_fact:
        cuwr_num_peer_started_after_reboot : "{{ cuwr_num_peer_started_after_reboot + [FollowerUUIDs[item]] }}"
      loop: "{{ range(0, npeers_for_leader_elect | int - 1) | list }}"

    - name: "{{ recipe_name }}: Activate Raft timer thread on all started peers."
      vars:
        stage: "idle_off"
        cmd: "ignore_timer_events@false"
        where: "/raft_net_info/ignore_timer_events"
      debug:
        msg: "{{ lookup('niova_ctlrequest', 'apply_cmd', cuwr_num_peer_started_after_reboot, cmd, where) }}"
      no_log: True

    #6 - Wait for an Election to Complete (Wait for 5 minutes).
    - name: "{{ recipe_name }}: Wait until leader election happens."
      vars:
        stage: "leader_election"
      debug:
        msg: "Waiting for leader election"
      until: lookup('niova_ctlrequest', 'lookup', cuwr_num_peer_started_after_reboot[item], '/raft_root_entry/0/leader-uuid')['/0/leader-uuid'] != "null"
      retries: 300
      delay: 1
      loop: "{{ range(0, cuwr_num_peer_started_after_reboot | length) | list }}"
      failed_when: lookup('niova_ctlrequest', 'lookup', cuwr_num_peer_started_after_reboot[item], '/raft_root_entry/0/leader-uuid')['/0/leader-uuid'] == "null"

    #Verify that leader before reboot and after reboot are same.
    - name: "{{ recipe_name }}: Get leader_uuid after reboot."
      vars:
        stage: "leader_after_reboot"
        raft_keys:
               - "/raft_root_entry/0/leader-uuid"
        raft_values_leader_after_reboot: "{{ lookup('niova_ctlrequest', 'lookup', cuwr_num_peer_started_after_reboot[0], raft_keys) }}"
      with_items:
          - "{{ raft_values_leader_after_reboot }}"
      debug:
        msg: "Getting leader_uuid after reboot."
      register: leader_uuid_after

    - name: "{{ recipe_name }}: Verify that leader did not change after reboot."
      vars:
         cuwr_leader_uuid_before: "{{ leader_values['results'][0]['item']['/0/leader-uuid'] }}"
      debug:
        msg: "Verifying that leader did not change after reboot."
      failed_when: cuwr_leader_uuid_before != leader_uuid_after['results'][0]['item']['/0/leader-uuid']

    - name: "{{ recipe_name }}:Get remaining non-running peer uuids for restarting it."
      set_fact:
         cuwr_remaining_followers_to_start: "{{ FollowerUUIDs | difference(cuwr_num_peer_started_after_reboot) }}"

    #7 - Startup the Remaining Followers
    - name: "{{ recipe_name }}: Restarting remaining followers."
      include_role:
        name: common
        tasks_from: start_server
      vars:
        ServerUUID: "{{ cuwr_remaining_followers_to_start[item] }}"
      loop: "{{ range(0, cuwr_remaining_followers_to_start | length) | list }}"

    - name: "{{ recipe_name }}: Wait until all followers have a last-applied-idx which is equal to the leader's."
      vars:
        stage: "poll_for_last_applied_idx"
      debug:
        msg: "Waiting for all followers to have a last-applied-idx which is equal to the leader's."
      until: (lookup('niova_ctlrequest', 'lookup', FollowerUUIDs[item], '/raft_root_entry/0/last-applied')['/0/last-applied']) == (lookup('niova_ctlrequest', 'lookup', leader_uuid_after['results'][0]['item']['/0/leader-uuid'], '/raft_root_entry/0/last-applied')['/0/last-applied'])
      loop: "{{ range(0, FollowerUUIDs | length) | list }}"
      loop_control:
         pause: 2

    #7a - Verifications
    - name: "{{ recipe_name }}: Get the values for comparing commit-idx, last-applied and sync-entry-idx for all servers."
      vars:
        stage: "verifications_after_reboot"
        raft_root_entry_all_after_vals: "{{ lookup('niova_ctlrequest', 'lookup', NRunningPeers, peer_raft_keys) }}"
      debug:
        msg: "Getting values for for all peers for comparing commit-idx, last-applied and sync-entry-idx."
      with_items:
          - "{{ raft_root_entry_all_after_vals }}"
      register: raft_root_entry_all_after

    - name: "{{ recipe_name }}: Verify values for commit-idx, last-applied and sync-entry-idx for all servers."
      vars:
        commit_idx: "{{ raft_root_entry_all_after['results'][item]['item'] }}"
        last_applied: "{{ raft_root_entry_all_after['results'][item]['item'] }}"
        sync_entry_idx: "{{  raft_root_entry_all_after['results'][item]['item'] }}"
        commit_idx_prev: "{{ raft_root_entry_all['results'][item]['item'] }}"
        last_applied_prev: "{{ raft_root_entry_all['results'][item]['item'] }}"
        sync_entry_idx_prev: "{{  raft_root_entry_all['results'][item]['item'] }}"
      debug:
        msg: "Verifying values for commit-idx, last-applied and sync-entry-idx for all servers."
      failed_when: >
            (commit_idx['/0/commit-idx'] <= (commit_idx_prev['/0/commit-idx'])) or
            (last_applied['/0/last-applied'] <= (last_applied_prev['/0/last-applied'])) or
            (sync_entry_idx['/0/sync-entry-idx'] <= (sync_entry_idx_prev['/0/sync-entry-idx']))
      loop: "{{ range(0, NRunningPeers | length) | list }}"

    - name: "{{ recipe_name }}: Validate term, last-applied-cumulative-crc, sync-entry-term, sync-entry-data-size and sync-entry-crc of all peers after reboot."
      vars:
        term: "{{ raft_root_entry_all_after['results'][item]['item']['/0/term'] }}"
        last_applied_cum_crc: "{{ raft_root_entry_all_after['results'][item]['item']['/0/last-applied-cumulative-crc'] }}"
        sync_entry_term: "{{ raft_root_entry_all_after['results'][item]['item']['/0/sync-entry-term'] }}"
        sync_entry_data_size: "{{ raft_root_entry_all_after['results'][item]['item']['/0/sync-entry-data-size'] }}"
        sync_entry_crc: "{{ raft_root_entry_all_after['results'][item]['item']['/0/sync-entry-crc'] }}"
        term_next: "{{ raft_root_entry_all_after['results'][item + 1]['item']['/0/term'] }}"
        last_applied_cum_crc_next: "{{ raft_root_entry_all_after['results'][item + 1]['item']['/0/last-applied-cumulative-crc'] }}"
        sync_entry_term_next: "{{ raft_root_entry_all_after['results'][item + 1]['item']['/0/sync-entry-term'] }}"
        sync_entry_data_size_next: "{{ raft_root_entry_all_after['results'][item + 1]['item']['/0/sync-entry-data-size'] }}"
        sync_entry_crc_next: "{{ raft_root_entry_all_after['results'][item + 1]['item']['/0/sync-entry-crc'] }}"
      debug:
        msg: "Compare raft_root_entry values of all peers"
      failed_when: >
            (term != term_next) or
            (last_applied_cum_crc != last_applied_cum_crc_next) or
            (sync_entry_term != sync_entry_term_next) or
            (sync_entry_data_size != sync_entry_data_size_next) or
            (sync_entry_crc != sync_entry_crc_next)
      loop: "{{ range(0, NRunningPeers | length-1) | list }}"

    #8 - Verify the Application Data.
    - name: "{{ recipe_name }}: Perform read on the same object."
      vars:
        stage: "read"
        cmd: "input@{{ app_uuid.stdout }}:0:0:0:0.read"
        where: "/pumice_db_test_client/input"
      debug:
        msg: "{{ lookup('niova_ctlrequest', 'apply_cmd', client_uuid.stdout, cmd, where) }}"
      no_log: True

    #8a- Get values for pmdb-request-history.
    - name: "{{ recipe_name }}: Get values for pmdb-request-history."
      vars:
        stage: "pmdb_request_history"
        raft_keys:
            - "/pumice_db_test_client/pmdb-request-history"
        pmdb_req_history_vals: "{{ lookup('niova_ctlrequest', 'lookup', client_uuid.stdout, raft_keys) }}"
      debug:
        msg: "Getting values for pmdb-request-history."
      with_items:
          - "{{ pmdb_req_history_vals }}"
      register: pmdb_request_history
      no_log: True

    #8a- Verifications.
    - name: "{{ recipe_name }}: Validate pmdb-request-history parameters."
      vars:
        rncui: "{{ app_uuid.stdout }}:0:0:0:0"
        pmdb_seqno: "{{ pmdb_request_history['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
        app_seq_no: "{{ pmdb_request_history['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
        app_user_id: "{{ pmdb_request_history['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
        op: "{{ pmdb_request_history['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
        status: "{{ pmdb_request_history['results'][0]['item']['/pumice_db_test_client/pmdb-request-history'][0] }}"
      debug:
        msg: 
          - "Validating pmdb-request-history parameters."
          - "{{ pmdb_request_history }}"
      failed_when: >
            (pmdb_seqno['pmdb-seqno'] != 0) or
            (app_seq_no['app-seqno'] != 1) or
            (app_user_id['app-user-id'] != rncui) or
            (op['op'] != "read") or
            (status['status'] != "Success")

    # Recipe Cleanup
    - name: "{{ recipe_name }}: Reset the client request timeout to default timeout i.e. 60sec."
      vars:
         stage: "reset_cli_timeout"
         cmd: "default-request-timeout-sec@60"
         where: "/raft_client_root_entry/default-request-timeout-sec"
      debug:
        msg: "{{ lookup('niova_ctlrequest', 'apply_cmd', client_uuid.stdout, cmd, where) }}"
      no_log: True

    rescue:
      - name: "Recipe: {{ recipe_name }} failed"
        set_fact:
           terminate_recipe: true
